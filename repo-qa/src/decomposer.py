"""ç­–ç•¥æ€§é—®é¢˜åˆ†è§£å™¨ - Code-Specific ç‰ˆæœ¬ï¼ˆStage 1 æ ¸å¿ƒè´¡çŒ®ï¼‰"""
import json
import re
from typing import Dict, List, Optional, Any

class StrategicDecomposer:
    """Code-Specific åˆ†è§£å™¨
    
    æ ¸å¿ƒç­–ç•¥ï¼š
    1. å¹¶è¡Œå…¨åˆ†ï¼ˆParallel Partitionï¼‰ï¼šè¯†åˆ«ç‹¬ç«‹åˆ‡é¢
    2. çº¿æ€§æˆªæ–­ï¼ˆLinear Truncationï¼‰ï¼šåªç»™å…¥å£ç‚¹
    3. ç¬¦å·é”šå®šï¼ˆSymbol Groundingï¼‰ï¼šåŸºäºä»£ç å›¾éªŒè¯
    """
    
    def __init__(self, model, code_graph: Optional['CodeGraph'] = None):
        self.model = model
        self.code_graph = code_graph
        self.last_result: Optional[Dict] = None
    
    def decompose(self, question: str) -> Dict:
        """åˆ†è§£é—®é¢˜ä¸ºç‹¬ç«‹åˆ‡é¢
        
        Args:
            question: åŸå§‹é—®é¢˜
            
        Returns:
            åˆ†è§£ç»“æœå­—å…¸
        """
        # Step 1: æå–å…³é”®ç¬¦å·
        symbols = self._extract_symbols(question)
        
        # Step 2: æ„å»ºå›¾ä¸Šä¸‹æ–‡ï¼ˆCode-Specific æ ¸å¿ƒï¼‰
        graph_context = self._build_graph_context(symbols)
        
        # Step 3: è°ƒç”¨ LLM åˆ†è§£
        prompt = self._build_decomposition_prompt(question, graph_context)
        response = self.model.query([{"role": "user", "content": prompt}])
        
        print("\nğŸ“‹ Decomposer Response:")
        print("=" * 60)
        print(response["content"])
        print("=" * 60 + "\n")
        
        # Step 4: è§£æå¹¶éªŒè¯
        result = self._parse_result(response["content"], question)
        result = self._normalize_result(result, question)
        self.last_result = result
        
        return result
    
    def _extract_symbols(self, question: str) -> List[str]:
        """ä»é—®é¢˜ä¸­æå–å¯èƒ½çš„ç¬¦å·å
        
        å¯å‘å¼è§„åˆ™ï¼š
        - é©¼å³°å‘½åï¼ˆå¦‚ DefaultAgent, LocalEnvironmentï¼‰
        - ä¸‹åˆ’çº¿å‘½åï¼ˆå¦‚ execute_action, timeout_errorï¼‰
        - Exception ç»“å°¾çš„è¯
        """
        symbols = []
        
        # é©¼å³°å‘½å
        camel_case = re.findall(r'\b[A-Z][a-zA-Z]+\b', question)
        symbols.extend(camel_case)
        
        # ä¸‹åˆ’çº¿å‘½åï¼ˆé•¿åº¦ >= 4ï¼‰
        snake_case = re.findall(r'\b[a-z_]{4,}\b', question)
        symbols.extend(snake_case)
        
        return list(set(symbols))
    
    def _build_graph_context(self, symbols: List[str]) -> str:
        """åŸºäºä»£ç å›¾æ„å»ºä¸Šä¸‹æ–‡ï¼ˆCode-Specific æ ¸å¿ƒï¼‰
        
        è¿™æ˜¯æœ¬æ–¹æ³•ç›¸æ¯”é€šç”¨åˆ†è§£å™¨çš„å…³é”®ä¼˜åŠ¿ï¼š
        ä½¿ç”¨é™æ€åˆ†ææä¾›å®¢è§‚çš„ä»£ç ç»“æ„ä¿¡æ¯
        """
        if not self.code_graph:
            return ""
        
        context_lines = ["CODE GRAPH ANALYSIS:"]
        found_any = False
        
        for symbol in symbols:
            # åœ¨å›¾ä¸­æœç´¢ç¬¦å·
            results = self.code_graph.search_symbol(symbol, limit=2)
            
            for result in results:
                qname = result.get('qname', result['name'])
                node_id = f"{result['file']}::{qname}"
                neighbors = self.code_graph.get_neighbors(node_id)
                
                # åªè¾“å‡ºæœ‰é‚»å±…å…³ç³»çš„èŠ‚ç‚¹ï¼ˆæ›´æœ‰ä»·å€¼ï¼‰
                if neighbors and (neighbors['calls'] or neighbors['called_by']):
                    found_any = True
                    context_lines.append(f"\n- Symbol: {qname}")
                    context_lines.append(f"  Location: {result['file']}:{result['line']}")
                    context_lines.append(f"  Type: {result['type']}")
                    
                    if neighbors['calls']:
                        context_lines.append(
                            f"  â†’ Calls: {', '.join(neighbors['calls'][:3])}"
                        )
                    if neighbors['called_by']:
                        context_lines.append(
                            f"  â† Called by: {', '.join(neighbors['called_by'][:3])}"
                        )
        
        if not found_any:
            return ""
        
        return "\n".join(context_lines)
    
    def _build_decomposition_prompt(self, question: str, graph_context: str) -> str:
        """æ„å»ºåˆ†è§£ Promptï¼ˆStage 1 æ ¸å¿ƒè®¾è®¡ï¼‰"""
        return f"""You are a Code-Specific Multi-hop QA Decomposition Expert.

TASK: Decompose the following code question into INDEPENDENT SUB-QUESTIONS.

PRINCIPLES:
1. PARALLEL PARTITION: Identify ALL independent aspects (different modules/classes)
   - If the question involves multiple modules, list them separately
   - Do NOT force a single reasoning chain

2. LINEAR TRUNCATION: Specify ENTRY CANDIDATES only, NOT reasoning steps
   - Format: "file.py::ClassName.method_name" or "file.py::function_name"
   - Provide 1~3 graph-grounded candidates
   - Do NOT predict what happens next - the agent will explore dynamically

3. SYMBOL GROUNDING: Use symbols from CODE GRAPH ANALYSIS
   - Prioritize symbols that appear in the graph
   - If a symbol is not found, keep it in unresolved_symbols

QUESTION:
{question}

{graph_context}

OUTPUT FORMAT (JSON only, no markdown):
{{
  "sub_questions": [
    {{
      "sub_question": "A concrete and answerable question?",
      "hypothesis": "A falsifiable expectation",
      "entry_candidates": ["exact_file.py::ExactClass.method_name"],
      "symbols": ["Symbol1", "Symbol2"],
      "required_evidence": ["definition location", "call path"],
      "exit_criterion": "What counts as done",
      "status": "open",
      "priority": 1
    }}
  ],
  "synthesis": "How to combine findings from all aspects",
  "estimated_hops": 2,
  "unresolved_symbols": []
}}

CRITICAL REQUIREMENTS:
- sub_question MUST be explicit question sentence
- Entry candidates MUST be PRECISE (Class.method level, not just Class)
- Use symbols from CODE GRAPH ANALYSIS above whenever possible
- DO NOT predict reasoning steps, ONLY entry points
- Output ONLY valid JSON, no extra text
"""

    def _normalize_result(self, result: Dict[str, Any], question: str) -> Dict[str, Any]:
        """å°† LLM è¾“å‡ºæ ‡å‡†åŒ–ä¸ºå¯ç”¨äºåç»­ RL çš„ç»“æ„ã€‚

        - ä¿æŒå¯¹æ—§å­—æ®µ aspects çš„å‘åå…¼å®¹ã€‚
        - ç»Ÿä¸€äº§å‡º sub_questionsï¼ŒåŒ…å«æ˜¾å¼å¯æ›´æ–°çŠ¶æ€å­—æ®µã€‚
        """
        raw_items = result.get("sub_questions")
        if not isinstance(raw_items, list):
            raw_items = result.get("aspects", [])

        normalized: List[Dict[str, Any]] = []
        for idx, item in enumerate(raw_items, 1):
            if not isinstance(item, dict):
                continue

            entry_candidates = item.get("entry_candidates")
            if not isinstance(entry_candidates, list) or not entry_candidates:
                legacy_entry = item.get("entry_point", "unknown")
                entry_candidates = [legacy_entry]

            sub_question = item.get("sub_question") or item.get("description")
            if not sub_question:
                sub_question = f"What is the role of aspect {idx} for this question?"
            if "?" not in sub_question:
                sub_question = sub_question.rstrip(".") + "?"

            required_evidence = item.get("required_evidence")
            if not isinstance(required_evidence, list) or len(required_evidence) < 2:
                required_evidence = ["definition location", "call path"]

            normalized_item = {
                "id": item.get("id", f"SQ{idx}"),
                "sub_question": sub_question,
                "hypothesis": item.get("hypothesis", "To be validated from code evidence"),
                "entry_candidates": entry_candidates[:3],
                "symbols": item.get("symbols", []),
                "required_evidence": required_evidence,
                "exit_criterion": item.get(
                    "exit_criterion",
                    "At least 2 grounded evidence items with file path and line references"
                ),
                "status": item.get("status", "open"),
                "priority": item.get("priority", idx),
                "evidence_found": [],
                "progress": 0.0,
                "attempts": 0,
            }
            normalized.append(normalized_item)

        if not normalized:
            fallback = self._create_fallback(question)
            return self._normalize_result(fallback, question)

        result["sub_questions"] = sorted(normalized, key=lambda x: x.get("priority", 999))
        # å…¼å®¹æ—§ prompt é€»è¾‘
        result["aspects"] = [
            {
                "description": sq["sub_question"],
                "entry_point": sq["entry_candidates"][0] if sq["entry_candidates"] else "unknown",
                "symbols": sq.get("symbols", []),
                "priority": sq.get("priority", 99),
            }
            for sq in result["sub_questions"]
        ]
        result.setdefault("unresolved_symbols", [])
        result.setdefault("synthesis", "Synthesize all validated sub-question answers")
        result.setdefault("estimated_hops", max(1, len(result["sub_questions"])))
        return result
    
    def _parse_result(self, content: str, question: str) -> Dict:
        """è§£æ LLM è¿”å›çš„ JSON ç»“æœ"""
        try:
            # æ¸…ç† markdown ä»£ç å—
            content = re.sub(r'^```json\s*', '', content, flags=re.MULTILINE)
            content = re.sub(r'^```\s*', '', content, flags=re.MULTILINE)
            content = re.sub(r'\s*```$', '', content)
            content = content.strip()
            
            # æå– JSON
            match = re.search(r'\{.*\}', content, re.DOTALL)
            if match:
                result = json.loads(match.group())
                
                # éªŒè¯å¿…éœ€å­—æ®µï¼ˆå…¼å®¹ sub_questions / aspectsï¼‰
                if 'sub_questions' in result and isinstance(result['sub_questions'], list):
                    if len(result['sub_questions']) > 0:
                        print(f"âœ“ Decomposition successful: {len(result['sub_questions'])} sub-questions")
                        return result
                if 'aspects' in result and isinstance(result['aspects'], list):
                    if len(result['aspects']) > 0:
                        print(f"âœ“ Decomposition successful: {len(result['aspects'])} aspects")
                        return result
        
        except json.JSONDecodeError as e:
            print(f"âš ï¸  JSON parse error: {e}")
        except Exception as e:
            print(f"âš ï¸  Unexpected error: {e}")
        
        # è¿”å› fallback
        print("âš ï¸  Using fallback decomposition")
        return self._create_fallback(question)
    
    def _create_fallback(self, question: str) -> Dict:
        """åˆ›å»º fallback åˆ†è§£ç»“æœ"""
        return {
            "sub_questions": [
                {
                    "id": "SQ1",
                    "sub_question": f"How can we answer: {question[:60]}?",
                    "hypothesis": "Need direct code evidence before concluding",
                    "entry_candidates": ["unknown"],
                    "symbols": self._extract_symbols(question),
                    "required_evidence": ["definition location", "call path"],
                    "exit_criterion": "At least 2 grounded evidence items with line refs",
                    "status": "open",
                    "priority": 1,
                }
            ],
            "synthesis": "Answer based on code exploration",
            "estimated_hops": 1,
            "unresolved_symbols": [],
        }
